---
title: "Exporta vs No exporta con K-NN"
output: html_notebook
date: 2020-09-15
author: "Nicolás Stumberger"
---

Con el objetivo de aplicar el algoritmo de clasificiación denominado k-NN sobre datos reales, llevé adelante este análisis que tiene la intención de predecir si una empresa va a realizar una exportación (o no) durante el próximo año en base a variables que, puede suponerse, tienen cierta incidencia en la performance de las exportaciones de una empresa.

# Indice

1.  Sobre k-NN
2.  Sobre los datos
3.  Pasos

3.1. Obtención de datos\
3.2. Exploración y preparación de datos\
3.3. Entrenando el modelo\
3.4. Evaluando la performance del modelo\
3.5. Mejorando la performance del modelo

4.  Conclusiones y disparadores

# 1. Sobre el algoritmo k-NN

## "Dios los cría y ellos se juntan"

El algoritmo k-NN, por su siglas en inglés (k Nearest Neighbords: k Vecinos Cercanos) tiene por objetivo clasificar datos y colocarlos en la misma categoría de la de los "vecinos cercanos", por ser similares en otras caracterísitcas. Las cosas que son parecidas, comúnmente tienen propiedades parecidas. En este caso, la hipótesis sería que los exportadores parecidos tendrán un resultado parecido durante el próximo año. La "clasificación" es la etiqueta que queremos predecir, llamada "target feature".

Entonces, lo que hace este algoritmo es tomar observaciones sin clasificar (registros "nuevos") y les asigna la etiqueta de la clasificación de observaciones similares. Para encontrar esa similitud, se toma variables (features) disponibles.

Ahora bien, ¿cómo calcula el algoritmo la cercanía entre las observaciones (entre las empresas en este caso)? Sintéticamente, utiliza un cálculo para medir distancias entre las variables de cada observación, llamado "distancia euclidiana", el cual se deduce a partir del Teorema de Pitágoras.

No es foco de este análisis entrar en detalles sobre el algoritmo (ya que hay mucha información al respecto en la web), pero sí me interesa destacar un par de aspectos más. Primero, este algoritmo se lo describe como "lazy" (vago, perezoso), porque en realidad no produce un modelo (no se produce ninguna abstracción), sino que utiliza los mismos datos para realizar la clasificación y, por esto mismo, la posibilidad de entender cómo cada variable está relacionada con el resultado (clasificación) está bastante limitada. Por este motivo, este análisis no tendrá un resultado explicativo, sino que será únicamente predictivo.

Segundo, el algoritmo funciona únicamente con variables numéricas, por lo que cualquier variable categórica (si existiera, y en este caso existen) debe convertirse a una numérica creando variables "dummy" (proceso conocido como "dummy coding" o "one-hot encoding").

# 2. Sobre los datos

Los datos que se utilizaron para crear el análisis vienen una fuente privada que recopila datos de aduana. A los efectos de este análisis, las observaciones se agregaron a nivel anual por empresa. Estas últimas fueron anonimizadas. El rango de años tomados para el análisis es 2014-2019, utilizando el último año como target feature y no se lo utiliza para el algoritmo.

Existen límites respecto a la cantidad de variables que se pueden utilizar. La cantidad y qué variables cuenta la fuente primaria opera como uno de ellos. La otra restricción es más subjetiva y en este caso fue delimitada para que la etapa de preparación de datos, denominada "data wrangling" (o "data carpentry") no consuma demasiado tiempo, consiguiendo que este análisis nunca vea la luz.

Entre ambos límites, se encuentra este sweet spot (en mi opinión) de utilizar las variables mencionadas. Esto no quiere decir que la selección de atributos sea azaroza. Los mismos se sustentan en ciertas hipótesis sobre su relevancia en la performance exportadora de las empresas: diversificación de cartera de productos; diversificación de destinos; regiones más estables que otras como mercados de destino; industrias más estables que otras; volúmenes exportados.

Como resultado, las variables que se utilizaron para realizar este análisis son:

1.  Número (cantidad ) de posiciones arancelarias distintas a nivel NCM (por cada año analizado): 5 variables.
2.  Número (cantidad) de países distintos a los que se exportó (por cada año analizado): 5 variables.
3.  Número (cantidad) de países destino por región del mundo: Latinoamérica, Europa, Asia-Pacífico, Maghreb y Medio Oriente, Resto de África, Norteamérica, Oceanía, Comunidad de Estados Independientes y Otros: 8 variables.
4.  Gran rubro (variables dummy): las posiciones arancelarias exportadas a qué Gran Rubro (clasificación de INDEC) pertenece: Manufacturas de Origen Agrícola, Manufacturas de Origien Industrial, Productos Primarios, Combustible y Energía: 4 variables.
5.  Dólares FOB exportados por año: 5 variables

La descripción de este análisis no incluye todo el proceso de "data carpentry" realizado. Se dice que la etapa de preparación de datos ocupa más del 80% del proceso de análisis. Sin embargo, en este caso creo que fue cerca del 95%. Como el objetivo de este informe no es "data carpentry", consideré prescindible incluirlo y focalizarme en el tema del asunto.

# 3. Prediciendo si una empresa exportará (o no) el próximo año con k-NN

## 3.1. Obtención de datos

Tal como se mendiona arriba, los datos fueron procesados previamente. El resultado de ese data carpentry es el dataset exportadores\_prep.RDS.

```{r}
exportadores <- readRDS(file = "data/exportadores_prep.RDS")
```

El dataset cuenta con un poco más de 16.000 filas, representando exportadores, y 29 columnas. La primera es id del exportador, la segunda es el target feature (la variable que queremos predecir) que indica si la empresa exportó o no en el último año. El resto de las variables (27 ) son los atributos que utilizaremos para predecir.

```{r}
str(exportadores)
```

La tabla metadatos tiene la descripción de cada campo:

```{r}
metadatos <-
        xlsx::read.xlsx2(file = "data/metadatos.xlsx", 
                         sheetName = "metadatos")

metadatos
```

## 3.2. Exploración y preparación de datos

## 3.3. Entrenando el modelo

## 3.4. Evaluando la performance del modelo

## 3.5. Mejorando la performance del modelo

# 4. Conclusiones y disparadores
